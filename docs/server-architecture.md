# MemoryX 服务器架构图

## 架构概览

```
                                    ┌─────────────────────────────────────────────────────────────────────┐
                                    │                          用户请求                                    │
                                    └─────────────────────────────────────────────────────────────────────┘
                                                              │
                                                              ▼
                                    ┌─────────────────────────────────────────────────────────────────────┐
                                    │              统一入口: 192.168.31.65:11436                          │
                                    │                    (BGE-M3 服务器)                                  │
                                    └─────────────────────────────────────────────────────────────────────┘
                                                              │
                                           ┌──────────────────┴──────────────────┐
                                           │                                     │
                                           ▼                                     ▼
                              ┌────────────────────────┐            ┌────────────────────────┐
                              │    嵌入服务 (本地)      │            │    LLM服务 (转发)       │
                              │    /v1/embeddings      │            │    /v1/chat/completions │
                              │    /v1/rerank          │            │    /qwen/*              │
                              └────────────────────────┘            └────────────────────────┘
                                           │                                     │
                                           │                                     │
                                           ▼                                     ▼
                              ┌────────────────────────┐            ┌─────────────────────────────────────────────────────────────────────┐
                              │   192.168.31.65        │            │                      192.168.31.10:11434                         │
                              │   BGE-M3 双P40         │            │                         NGINX 负载均衡                          │
                              └────────────────────────┘            └─────────────────────────────────────────────────────────────────────┘
                                                                                         │
                                                                        ┌────────────────┼────────────────┐
                                                                        │                │                │
                                                                        ▼                ▼                ▼
                                                              ┌──────────────┐  ┌──────────────┐  ┌──────────────┐
                                                              │ Llama Backend│  │ Llama Backend│  │ Qwen Backend │
                                                              │  (实体提取)   │  │  (实体提取)   │  │  (记忆判断)   │
                                                              │  GPU 0 + 1   │  │  GPU 0 + 1   │  │    GPU 2     │
                                                              └──────────────┘  └──────────────┘  └──────────────┘
```

---

## 服务器详情

### 服务器 1: 192.168.31.65 (BGE-M3 嵌入服务)

| 组件 | 详情 |
|------|------|
| **GPU** | 2x NVIDIA P40 (24GB) |
| **功能** | 向量嵌入、重排序 |
| **统一入口端口** | 11436 |
| **YAML位置** | `/data/ollama_models/bge-ha.yaml` |
| **NGINX配置** | `/data/ollama_models/nginx-unified.conf` |

#### 容器布局

```
┌─────────────────────────────────────────────────────────────────┐
│                    192.168.31.65 (BGE Server)                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────────────┐     ┌─────────────────┐                   │
│  │   bge-gpu0      │     │   bge-gpu1      │                   │
│  │   Port: 11431   │     │   Port: 11432   │                   │
│  │   GPU: 0        │     │   GPU: 1        │                   │
│  └────────┬────────┘     └────────┬────────┘                   │
│           │                       │                             │
│           └───────────┬───────────┘                             │
│                       │                                         │
│                       ▼                                         │
│           ┌─────────────────────┐                               │
│           │   NGINX (统一入口)   │                               │
│           │   Port: 11436       │ ◄─── 用户请求入口              │
│           └──────────┬──────────┘                               │
│                      │                                          │
│                      ├────► /v1/embeddings ──► BGE 负载均衡     │
│                      ├────► /v1/rerank ──────► BGE 负载均衡     │
│                      │                                          │
│                      └────► /v1/chat/completions                │
│                             /qwen/*                             │
│                                    │                            │
│                                    ▼                            │
│                           转发到 192.168.31.10:11434            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### 服务器 2: 192.168.31.10 (LLM 推理服务)

| 组件 | 详情 |
|------|------|
| **GPU** | 3x NVIDIA V100 (32GB) |
| **功能** | 实体提取、事实提取、记忆判断、逻辑推理 |
| **入口端口** | 11434 |
| **YAML位置** | `/data/projects/models/memoryx-hybrid.yaml` |
| **NGINX配置** | `/data/projects/models/nginx-hybrid.conf` |

#### 容器布局

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│                              192.168.31.10 (LLM Server)                                 │
├─────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐   │
│  │                              GPU 0 (15.7GB / 32GB)                               │   │
│  │  ┌─────────────────────────────┐    ┌─────────────────────────────┐             │   │
│  │  │   vllm_llama_gpu0_0         │    │   vllm_llama_gpu0_1         │             │   │
│  │  │   Model: Llama-3.1-8B-INT4  │    │   Model: Llama-3.1-8B-INT4  │             │   │
│  │  │   Port: 11401               │    │   Port: 11402               │             │   │
│  │  │   用途: 实体/事实提取         │    │   用途: 实体/事实提取         │             │   │
│  │  └─────────────────────────────┘    └─────────────────────────────┘             │   │
│  └─────────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐   │
│  │                              GPU 1 (15.7GB / 32GB)                               │   │
│  │  ┌─────────────────────────────┐    ┌─────────────────────────────┐             │   │
│  │  │   vllm_llama_gpu1_0         │    │   vllm_llama_gpu1_1         │             │   │
│  │  │   Model: Llama-3.1-8B-INT4  │    │   Model: Llama-3.1-8B-INT4  │             │   │
│  │  │   Port: 11403               │    │   Port: 11404               │             │   │
│  │  │   用途: 实体/事实提取         │    │   用途: 实体/事实提取         │             │   │
│  │  └─────────────────────────────┘    └─────────────────────────────┘             │   │
│  └─────────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐   │
│  │                              GPU 2 (27.5GB / 32GB)                               │   │
│  │  ┌───────────────────────────────────────────────────────────────────────────┐  │   │
│  │  │   vllm_qwen3_sft_gpu2                                                      │  │   │
│  │  │   Model: Qwen3-14B-Instruct-2512-SFT-GPTQ-Int8                             │  │   │
│  │  │   Port: 11405                                                              │  │   │
│  │  │   用途: 记忆判断、逻辑推理                                                    │  │   │
│  │  │   特点: 无思考模式、0.35s极速响应                                            │  │   │
│  │  └───────────────────────────────────────────────────────────────────────────┘  │   │
│  └─────────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐   │
│  │                                 NGINX 负载均衡                                   │   │
│  │                                 Port: 11434                                     │   │
│  │  ┌───────────────────────────────────────────────────────────────────────────┐  │   │
│  │  │  upstream llama_backend: 11401, 11402, 11403, 11404 (least_conn)          │  │   │
│  │  │  upstream qwen_backend:  11405                                            │  │   │
│  │  └───────────────────────────────────────────────────────────────────────────┘  │   │
│  └─────────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 请求路径详解

### 1. 向量嵌入请求

```
用户请求
    │
    ▼
POST http://192.168.31.65:11436/v1/embeddings
    │
    ▼
NGINX (31.65)
    │
    ├──► bge-gpu0:11431 (weight=1)
    │
    └──► bge-gpu1:11432 (weight=1)
    │
    ▼
返回向量 (1024维)
```

**示例请求:**
```bash
curl -X POST http://192.168.31.65:11436/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{
    "model": "bge-m3",
    "input": "用户喜欢喝咖啡"
  }'
```

---

### 2. 实体提取请求 (Llama)

```
用户请求
    │
    ▼
POST http://192.168.31.65:11436/v1/chat/completions
    │
    ▼
NGINX (31.65) ──转发──► NGINX (31.10:11434)
                              │
                              ▼
                    llama_backend (least_conn)
                              │
          ┌───────────────────┼───────────────────┐
          │                   │                   │
          ▼                   ▼                   ▼
    11401 (GPU0-0)     11402 (GPU0-1)     11403 (GPU1-0) ...
          │
          ▼
    返回提取的实体JSON
```

**示例请求:**
```bash
curl -X POST http://192.168.31.65:11436/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.1-8b",
    "messages": [
      {"role": "user", "content": "从以下文本提取实体：张三在北京阿里云工作"}
    ],
    "max_tokens": 100
  }'
```

---

### 3. 记忆判断请求 (Qwen3-SFT)

```
用户请求
    │
    ▼
POST http://192.168.31.65:11436/qwen/v1/chat/completions
    │
    ▼
NGINX (31.65) ──转发──► NGINX (31.10:11434)
                              │
                              ▼
                       /qwen/ 路由
                              │
                              ▼
                    qwen_backend (11405)
                              │
                              ▼
                    Qwen3-14B-SFT (GPU2)
                              │
                              ▼
              返回 {"type": "ADD/UPDATE/IGNORE"}
```

**示例请求:**
```bash
curl -X POST http://192.168.31.65:11436/qwen/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3-14b-sft",
    "messages": [
      {"role": "user", "content": "判断记忆操作类型。已有记忆：用户喜欢喝咖啡。新记忆：用户今天买了一杯拿铁。规则：新信息返回ADD，更新返回UPDATE，重复返回IGNORE。只返回JSON。"}
    ],
    "max_tokens": 30
  }'
```

---

## 配置文件位置

### 192.168.31.65 (BGE服务器)

| 文件 | 路径 | 用途 |
|------|------|------|
| Docker Compose | `/data/ollama_models/bge-ha.yaml` | BGE双卡部署 |
| NGINX配置 | `/data/ollama_models/nginx-unified.conf` | 统一入口+转发 |

### 192.168.31.10 (LLM服务器)

| 文件 | 路径 | 用途 |
|------|------|------|
| Docker Compose | `/data/projects/models/memoryx-hybrid.yaml` | LLM混合部署 |
| NGINX配置 | `/data/projects/models/nginx-hybrid.conf` | LLM负载均衡 |

---

## 端口映射表

### 192.168.31.65

| 端口 | 服务 | 说明 |
|------|------|------|
| 11431 | bge-gpu0 | BGE-M3 GPU0 |
| 11432 | bge-gpu1 | BGE-M3 GPU1 |
| 11436 | nginx | **统一入口** |

### 192.168.31.10

| 端口 | 服务 | 说明 |
|------|------|------|
| 11401 | vllm_llama_gpu0_0 | Llama GPU0实例1 |
| 11402 | vllm_llama_gpu0_1 | Llama GPU0实例2 |
| 11403 | vllm_llama_gpu1_0 | Llama GPU1实例1 |
| 11404 | vllm_llama_gpu1_1 | Llama GPU1实例2 |
| 11405 | vllm_qwen3_sft_gpu2 | Qwen3-SFT GPU2 |
| 11434 | nginx | LLM入口 |

---

## 模型文件位置

| 模型 | 路径 | 服务器 |
|------|------|--------|
| BGE-M3 | `/data/models/bge-m3` | 192.168.31.65 |
| Llama-3.1-8B-INT4 | `/data/projects/models/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4` | 192.168.31.10 |
| Qwen3-14B-SFT-INT8 | `/data/projects/models/Qwen3-14B-Instruct-2512-SFT-GPTQ-Int8` | 192.168.31.10 |

---

## 功能与模型对应表

| 功能 | 模型 | 请求路径 | 后端 |
|------|------|----------|------|
| 向量嵌入 | BGE-M3 | `/v1/embeddings` | bge-gpu0/1 |
| 重排序 | BGE-M3 | `/v1/rerank` | bge-gpu0/1 |
| 实体提取 | Llama-3.1-8B | `/v1/chat/completions` | llama_backend |
| 事实提取 | Llama-3.1-8B | `/v1/chat/completions` | llama_backend |
| 关系提取 | Llama-3.1-8B | `/v1/chat/completions` | llama_backend |
| 记忆判断 | Qwen3-14B-SFT | `/qwen/v1/chat/completions` | qwen_backend |
| 逻辑推理 | Qwen3-14B-SFT | `/qwen/v1/chat/completions` | qwen_backend |

---

## 运维命令

### 查看服务状态

```bash
# BGE服务器
ssh root@192.168.31.65 "docker ps | grep -E 'bge|nginx'"

# LLM服务器
ssh root@192.168.31.10 "docker ps | grep -E 'llama|qwen|nginx'"
```

### 重启服务

```bash
# 重启BGE
ssh root@192.168.31.65 "cd /data/ollama_models && docker-compose -f bge-ha.yaml restart"

# 重启LLM
ssh root@192.168.31.10 "docker restart vllm_nginx vllm_qwen3_sft_gpu2"
```

### 查看日志

```bash
# BGE日志
ssh root@192.168.31.65 "docker logs bge-gpu0 --tail 50"

# Qwen日志
ssh root@192.168.31.10 "docker logs vllm_qwen3_sft_gpu2 --tail 50"

# NGINX日志
ssh root@192.168.31.10 "docker logs vllm_nginx --tail 50"
```

### GPU状态

```bash
# BGE服务器
ssh root@192.168.31.65 "nvidia-smi"

# LLM服务器
ssh root@192.168.31.10 "nvidia-smi"
```

---

## 更新日志

- 2025-02-19: 创建架构文档，部署Qwen3-14B-SFT替换Qwen2.5-14B
